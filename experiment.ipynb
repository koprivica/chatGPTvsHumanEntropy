{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef0085c",
   "metadata": {},
   "source": [
    "# EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9158f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installation - do only one time\n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install PyPDF2\n",
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cbab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import - do only one time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197dd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions - do only one time\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "\n",
    "def extract_text_from_txt(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        text = \"\"\n",
    "        for line in lines:\n",
    "            text += line.strip()\n",
    "        return text\n",
    "\n",
    "def calculate_entropy(frequencies):\n",
    "    total_count = sum(frequencies.values())\n",
    "    entropy = 0.0\n",
    "    for count in frequencies.values():\n",
    "        probability = count / total_count\n",
    "        entropy += probability * math.log2(probability)\n",
    "    entropy = -entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "\n",
    "file_path = 'resources/chatgpt12.txt'\n",
    "output_path = 'results/chatgpt12.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Txt files\n",
    "\n",
    "text = extract_text_from_txt(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect text\n",
    "\n",
    "print(text[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tokens = [token.lower() for token in tokens]\n",
    "word_counts = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print total number of tokens (words)\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print token result\n",
    "\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ecb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from tokens\n",
    "\n",
    "df = pd.DataFrame.from_dict(word_counts, orient='index', columns=['Frequency'])\n",
    "df = df.sort_values(by='Frequency', ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec921f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result to excel\n",
    "\n",
    "df.to_excel(output_path, index_label='Token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f25083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort words - frequencies, extract values for calculations\n",
    "\n",
    "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "words = [word for word, count in sorted_word_counts]\n",
    "frequencies = [count for word, count in sorted_word_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calsulate entropy\n",
    "\n",
    "word_frequencies = dict(sorted_word_counts)\n",
    "entropy = calculate_entropy(word_frequencies)\n",
    "\n",
    "print(\"Entropy:\", entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Shannon entropy\n",
    "\n",
    "N = len(words) # Number of tokens\n",
    "Hmax = math.log2(N)\n",
    "equitability = entropy / Hmax\n",
    "\n",
    "print(\"Shannon entropy:\", equitability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bf7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(words)), frequencies, marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Zipf distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322476ea",
   "metadata": {},
   "source": [
    "# STATISTICS - Calculated after the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - Do only once\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets of Shannon entropy results - CAUSION: VALUES ARE ADDED MANUALLY AFTER CONDUCTING EXPERIMENT!!!!!\n",
    "humans = [0.833113900126817, 0.8271454592911431, 0.8308515612682966, 0.8260935292878034, 0.8046836710696255, 0.8032746326804925, 0.8275908995933942, 0.8195706120205691, 0.8292101326005887, 0.8049577285396834, 0.8074345124072044, 0.8361819144172309]\n",
    "chatgpt = [0.7803750294587815, 0.7809830951558806, 0.8158560359315511, 0.8291589192856613, 0.8157356267811509, 0.8203193596589072, 0.8031243808928831, 0.8161985942211579, 0.8191580234185233, 0.7998535368220583, 0.8013652965671577, 0.8051804650034923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "mean_humans = np.average(humans)\n",
    "print(mean_humans)\n",
    "mean_chatgpt = np.average(chatgpt)\n",
    "print(mean_chatgpt)\n",
    "\n",
    "print(\"Difference: \", str(mean_humans - mean_chatgpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "median_humans = np.median(humans)\n",
    "print(median_humans)\n",
    "median_chatgpt = np.median(chatgpt)\n",
    "print(median_chatgpt)\n",
    "\n",
    "print(\"Difference: \", str(median_humans - median_chatgpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975aebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "variance_humans = np.var(humans)\n",
    "print(variance_humans)\n",
    "variance_chatgpt = np.var(chatgpt)\n",
    "print(variance_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078aab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "stats.ttest_ind(a=humans, b=chatgpt, equal_var=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
